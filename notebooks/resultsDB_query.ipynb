{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b4be03e",
   "metadata": {},
   "source": [
    "# resultsDB Query Workflow\n",
    "\n",
    "Kat Nykiel, Alejandro Strachan\n",
    "\n",
    "This notebook demonstrates how to query results of the vaspingestor tool, and perform analysis to extract additional features for machine learning. Here, we use a high-throughput dataset of double-transition metal (DTM) MAX phases which have previously been loaded into the vaspingestor tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9307ecc3",
   "metadata": {},
   "source": [
    "## Load Sim2L Results\n",
    "We start by querying resultsDB for all DTM_MAX simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b479d381",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-16T16:29:59.941745Z",
     "start_time": "2023-06-16T16:29:40.985198Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from pymatgen.core import Structure, Composition\n",
    "from pymatgen.core.periodic_table import Element\n",
    "\n",
    "# Import nanoHUB-specific libraries\n",
    "import nanohubremote as nr\n",
    "from simtool import findInstalledSimToolNotebooks,searchForSimTool\n",
    "from simtool import getSimToolInputs,getSimToolOutputs,Run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2214e6b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-16T16:30:00.154824Z",
     "start_time": "2023-06-16T16:29:59.944442Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a nanoHUB web services session\n",
    "auth_data = {\n",
    "    'grant_type' : 'tool',\n",
    "}\n",
    "with open(os.environ[\"SESSIONDIR\"]+\"/resources\") as file:\n",
    "    lines = [line.split(\" \", 1) for line in file.readlines()]\n",
    "    properties = {line[0].strip(): line[1].strip() for line in lines if len(line)==2}\n",
    "    auth_data[\"sessiontoken\"] = properties[\"session_token\"]\n",
    "    auth_data[\"sessionnum\"] = properties[\"sessionid\"]\n",
    "    \n",
    "session = nr.Sim2l(auth_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee625d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-16T16:30:00.818116Z",
     "start_time": "2023-06-16T16:30:00.156864Z"
    }
   },
   "outputs": [],
   "source": [
    "# Query the vaspingestor tool for all runs submitted by Kat Nykiel with the DTM_MAX tag\n",
    "tool = 'vaspingestor'\n",
    "\n",
    "installedSimToolNotebooks = findInstalledSimToolNotebooks(tool,returnString=True)\n",
    "print(installedSimToolNotebooks)\n",
    "cellrelaxdft = searchForSimTool(tool)\n",
    "\n",
    "req_json = session.requestPost('dbexplorer/dbexplorer/search?simtool=true', data={ 'filters': '[{\"field\": \"input.author\", \"operation\": \"=\", \"value\": \"Kat '\n",
    "             'Nykiel\"},{\"field\": \"input.dataset\", \"operation\": \"=\", \"value\": \"DTM_MAX\"}]',\n",
    "  'limit': 10000,\n",
    "  'results': '['\n",
    "             '\"output.XC_functional\"]',\n",
    "  'revision': 0,\n",
    "  'tool': 'vaspingestor'}, timeout=20) # QUERY\n",
    "req_json = req_json.json()\n",
    "data = pd.DataFrame(req_json['results']).dropna().reset_index(drop=True) # Deleting columns with NaNs (you can comment this out)\n",
    "print(f'data size: {data.shape[0]}')\n",
    "squids = data['squid'].values\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfbd841",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-16T16:30:57.242393Z",
     "start_time": "2023-06-16T16:30:00.820053Z"
    }
   },
   "outputs": [],
   "source": [
    "# Obtain Sim2L outputs\n",
    "req_jsons = []\n",
    " \n",
    "for ids in np.array_split(squids,20):\n",
    "    search = {\n",
    "        'tool':'vaspingestor', \n",
    "        'filters':json.dumps([\n",
    "            {'field':'squid','operation':'in','value': str(tuple(ids))},\n",
    "        ]),\n",
    "        'results':json.dumps([\n",
    "            \"output.structure\", \"output.composition\", \n",
    "                 \"output.lattice_parameters\", \"output.lattice_angles\", \n",
    "                 \"output.energy\", \"output.forces\", \"output.max_force\", \n",
    "                 \"output.rms_force\", \"output.KPOINTS\", \"output.ENCUT\", \n",
    "                 \"output.XC_functional\"\n",
    "        ]),\n",
    "        'simtool' : 1,\n",
    "        'limit' : 500\n",
    "    }\n",
    "    req_json = session.requestPost('dbexplorer/dbexplorer/search', data=search)\n",
    "    req_json = req_json.json()\n",
    "    req_jsons.append(req_json)\n",
    "    \n",
    "req_dfs = []\n",
    "for req_json in req_jsons:\n",
    "    req_dfs.append(pd.DataFrame(req_json['results']))\n",
    "results_df = pd.concat(req_dfs)\n",
    "\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855bc82e",
   "metadata": {},
   "source": [
    "## Extract additional features\n",
    "Next, we extract additional features not stored in the Sim2L. These are features which either depend on outside simulations (formation energy, cohesive energy) or are MAX-specfic (bond lengths, interplanar distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feff5705",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-16T16:30:57.323185Z",
     "start_time": "2023-06-16T16:30:57.244468Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove unneccesary columns, strip 'output.' from column names\n",
    "results_df.drop('squid',axis=1,inplace=True)\n",
    "\n",
    "# create a dictionary to map old column names to new column names\n",
    "new_col_names = {col: col.replace('output.', '') for col in results_df.columns if col.startswith('output.')}\n",
    "\n",
    "# rename columns using the dictionary created above\n",
    "results_df.rename(columns=new_col_names, inplace=True)\n",
    "\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba2b659",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-16T16:32:57.516331Z",
     "start_time": "2023-06-16T16:32:19.413726Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_features(doc, e_df):\n",
    "    \"\"\"get set of extended features from Sim2L\n",
    "\n",
    "    Args:\n",
    "        doc (dict): row of pandas df from vaspingestor sim2L\n",
    "        e_df (DataFrame): Dataframe containing formation/cohesive energy values\n",
    "        \n",
    "    Returns:\n",
    "        features (dict): extracted feature dictionary\n",
    "    \"\"\"    \n",
    "\n",
    "    features = {}\n",
    "    \n",
    "    # Build structure object\n",
    "    struct = Structure.from_dict(doc['structure'])\n",
    "    n_map = {8:1,12:2,16:3}\n",
    "    n = n_map[struct.num_sites]\n",
    "    \n",
    "    # Formation and cohesive energies\n",
    "    comp_df = pd.DataFrame.from_dict(doc['composition'], orient='index', columns=['n'])\n",
    "    elements_df = e_df.set_index('element')\n",
    "    E_form = (comp_df['n'] * elements_df.loc[comp_df.index]['formation_energy']).sum()\n",
    "    E_coh = (comp_df['n'] * elements_df.loc[comp_df.index]['cohesive_energy']).sum()\n",
    "        \n",
    "    features['formation_energy_per_atom'] = (doc['energy'] - E_form)/struct.num_sites\n",
    "    features['cohesive_energy_per_atom'] = (doc['energy'] - E_coh)/struct.num_sites\n",
    "    \n",
    "    # Bond lengths\n",
    "    # r_MX\n",
    "    sites = {1:[0,6],2:[5,10],3:[7,13]}\n",
    "    features['r_MX'] = struct.get_distance(*sites[n])\n",
    "    # r_MA\n",
    "    sites = {1:[0,5],2:[3,6],3:[3,9]}\n",
    "    features['r_MA'] = struct.get_distance(*sites[n])\n",
    "\n",
    "    # Interplanar distances\n",
    "    # d_AA\n",
    "    sites = {1:[4,5],2:[6,7],3:[8,9]}\n",
    "    features['d_AA'] = get_z_distance(struct, *sites[n])\n",
    "    # d_MM\n",
    "    sites = {1:[0,2],2:[2,3],3:[1,3]}\n",
    "    features['d_MM'] = get_z_distance(struct, *sites[n])\n",
    "    # d_MX\n",
    "    sites = {1:[0,6],2:[5,10],3:[1,13]}\n",
    "    features['d_MX'] = get_z_distance(struct, *sites[n])\n",
    "    # d_XA\n",
    "    sites = {1:[5,6],2:[6,11],3:[8,13]}\n",
    "    features['d_XA'] = get_z_distance(struct, *sites[n])\n",
    "\n",
    "    # Add a few more features for plotting\n",
    "    features['c']=struct.lattice.abc[2]\n",
    "    species= [site.specie for site in struct]\n",
    "    uniques, i = np.unique(species,return_index=True)\n",
    "    sort_i = sorted(i)\n",
    "    elements = [s.symbol for s in [species[i] for i in sort_i]] \n",
    "    \n",
    "    if len(elements) == 4:\n",
    "        features['M1'] = elements[0]\n",
    "        features['M2'] = elements[1]\n",
    "        features['A'] = elements[2]\n",
    "        features['X'] = elements[3]\n",
    "    \n",
    "    elif len(elements) == 3:\n",
    "        features['M1'] = elements[0]\n",
    "        features['M2'] = elements[0]\n",
    "        features['A'] = elements[1]\n",
    "        features['X'] = elements[2]\n",
    "        \n",
    "    features['n']=n\n",
    "    \n",
    "    return features\n",
    "\n",
    "def get_z_distance(structure, site_idx1, site_idx2):\n",
    "    # return distance along z axis betwen two sites in Structure object\n",
    "    site1 = structure[site_idx1]\n",
    "    site2 = structure[site_idx2]\n",
    "    z_distance = abs(site1.coords[2] - site2.coords[2])\n",
    "    return z_distance\n",
    "\n",
    "with open('/home/nanohub/nykiel.4/vasp_ingestor/notebooks/energies.csv') as f:\n",
    "    e_df = pd.read_csv(f)\n",
    "\n",
    "features = []\n",
    "\n",
    "for index, doc in results_df.iterrows():\n",
    "    features.append(get_features(doc, e_df))\n",
    "\n",
    "feature_df = pd.DataFrame(features)\n",
    "feature_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cabddc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-16T16:32:57.610942Z",
     "start_time": "2023-06-16T16:32:57.519022Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add extracted features to results_df\n",
    "DTM_df = pd.concat([results_df.reset_index(),feature_df.reset_index()],axis=1)\n",
    "DTM_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67d6511",
   "metadata": {},
   "source": [
    "## Visualize Dataset\n",
    "Finally, we provide several plots to visualize the wide domain of this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934a4c83",
   "metadata": {},
   "source": [
    "### Scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dacc267",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-16T16:33:00.339242Z",
     "start_time": "2023-06-16T16:32:57.612808Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate 4 scatter plots of the data, colored by primary M', A, X elements and n number of layers\n",
    "for i,color in enumerate(['M1','A','X','n']):\n",
    "    titles = ['M\\'','A','X','n']\n",
    "    fig=go.Figure()\n",
    "    metals = DTM_df[color].unique()\n",
    "    colors = px.colors.qualitative.Prism\n",
    "    color_dict = dict(zip(metals,colors))\n",
    "    for metal in metals:\n",
    "        sdf = DTM_df[DTM_df[color]==metal]\n",
    "        try:\n",
    "            fig.add_trace(go.Scatter(x=sdf['c'],y=sdf['formation_energy_per_atom'], mode='markers',marker = {'color':color_dict[metal],'size':4}, name=str(metal))) #,col=i%2+1, row = i//2+1)\n",
    "        except KeyError:\n",
    "            print(f\"Could not generate a plot for {metal}\")\n",
    "    fig.update_layout(\n",
    "        xaxis_title='c (Å)',\n",
    "        yaxis_title='formation energy (eV/atom)',\n",
    "        # title=,\n",
    "        template='simple_white',\n",
    "        width=600,\n",
    "        height=600,\n",
    "        font_size=20,\n",
    "        legend=dict(x=.9,y=0.5,itemsizing='constant',title=titles[i])\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee47660e",
   "metadata": {},
   "source": [
    "### Violin plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a3a435",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-16T16:33:00.820022Z",
     "start_time": "2023-06-16T16:33:00.341168Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "metals = DTM_df.M1.unique()\n",
    "means = []\n",
    "for metal in metals:\n",
    "    means.append(np.mean(DTM_df[DTM_df['M1']==metal].formation_energy_per_atom.values))\n",
    "metals = [x for _, x in sorted(zip(means,metals))]\n",
    "for metal in metals:\n",
    "    fig.add_trace(go.Violin(x=DTM_df['M1'][DTM_df['M1']==metal][DTM_df['X']=='C'],y=DTM_df['formation_energy_per_atom'][DTM_df['M1']==metal][DTM_df['X']=='C'],name=f'{metal},C', side='positive',legendgroup='C',scalegroup='C',line_color='blue'))\n",
    "    fig.add_trace(go.Violin(x=DTM_df['M1'][DTM_df['M1']==metal][DTM_df['X']=='N'],y=DTM_df['formation_energy_per_atom'][DTM_df['M1']==metal][DTM_df['X']=='N'],name=f'{metal},N', side='negative',legendgroup='N',scalegroup='N',line_color='orange'))\n",
    "fig.update_traces(\n",
    "    meanline_visible=False,\n",
    "    points=False\n",
    ")\n",
    "fig.update_layout(\n",
    "    violingap=0,\n",
    "    violinmode='overlay',\n",
    "    xaxis_title='M\\' element',\n",
    "    yaxis_title='formation energy (eV/atom)',\n",
    "    # title='Formation energy vs. transition metal element',\n",
    "    template='simple_white',\n",
    "    showlegend=False,\n",
    "    font_size=16\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cadabb",
   "metadata": {},
   "source": [
    "### Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3a8a61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-16T16:37:29.919436Z",
     "start_time": "2023-06-16T16:37:29.447771Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "\n",
    "fig = make_subplots(rows=3, cols = 4, subplot_titles = [\"Al\",\"Si\",\"P\",\"S\",\"Ga\",\"Ge\",\"As\",\"Cd\",\"In\",\"Sn\",\"Tl\",\"Pb\"])\n",
    "\n",
    "for f,A in enumerate([\"Al\",\"Si\",\"P\",\"S\",\"Ga\",\"Ge\",\"As\",\"Cd\",\"In\",\"Sn\",\"Tl\",\"Pb\"]):\n",
    "\n",
    "    A_df = DTM_df[DTM_df.A==A]\n",
    "\n",
    "    # create a pivot table that maps col2 values to each unique col1 value\n",
    "    pivot = A_df.pivot_table(values='formation_energy_per_atom', index='M1', columns='M2')\n",
    "\n",
    "    # get the unique values of col1 and col2 from the original dataframe\n",
    "    x_labels = [\"Sc\",\"Ti\",\"V\",\"Cr\",\"Mn\",\"Zr\",\"Nb\",\"Mo\",\"Hf\",\"Ta\",\"W\"]\n",
    "    y_labels = x_labels\n",
    "\n",
    "    # create a list of dictionaries representing each row in the heatmap\n",
    "    rows = []\n",
    "    for i in range(len(y_labels)):\n",
    "        row = {'y': y_labels[i]}\n",
    "        for j in range(len(x_labels)):\n",
    "            value = pivot.loc[y_labels[i], x_labels[j]]\n",
    "            row[x_labels[j]] = value\n",
    "        rows.append(row)\n",
    "\n",
    "    # define the heatmap trace using the rows list and axis labels\n",
    "    fig.add_trace(go.Heatmap(z=[list(row.values())[1:] for row in rows],\n",
    "                    x=list(x_labels),\n",
    "                    y=list(y_labels),\n",
    "                    name=f'A={A}', coloraxis='coloraxis'),col = f%4+1, row = f//4+1)\n",
    "\n",
    "fig.for_each_annotation(lambda ann: ann.update(font=dict(size=22)))\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(4):\n",
    "        fig.update_xaxes(title_text='M\\' element', row=i+1, col = j+1)\n",
    "        fig.update_yaxes(title_text='M\\'\\' element', row=i+1, col=j+1)\n",
    "        \n",
    "fig.update_layout(\n",
    "    template='simple_white',\n",
    "    xaxis_title='M\\' element',\n",
    "    yaxis_title='M\\'\\' element',\n",
    "    width=1600,\n",
    "    height=1000,)\n",
    "fig.update_coloraxes(colorbar_title=dict(text='E<sub>form</sub>(eV/atom)'),colorbar_title_font_size=16)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f25a89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
